{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4311a1f-5492-4ac5-8839-ff272f144da5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 0. Introduction\n",
    "\n",
    "[This paper](https://link.springer.com/article/10.1007/s10822-021-00417-2) I recently came by discusses how to choose a classification model given the many possibilities available. As I read more on this subject, I decided to write this Notebook as a study guide. It ended up getting too big, and it has since been divided into more Notebooks/Tutorials, some that I still need to finish. I would appreciate any suggestions for their improvement.\n",
    "\n",
    "The main topics discussed in this Notebook are the methods available to compare two classification models and determine which one is a better choice (and the statistic significance of this choice).\n",
    "\n",
    "The other Notebooks discuss:\n",
    "- The Bayes error rate, which is the lowest possible error rate (which is 1 - accuracy) any classifier can achieve on a dataset, and how to estimate it. You can find it [here](https://github.com/rflameiro/projects/blob/main/Bayes_Error_Rate_Estimation.ipynb)\n",
    "- Estimation statistics: methods that go beyond hypothesis testing. I need to finish the discussion. Made a [notebook](https://github.com/rflameiro/projects/blob/main/R_REACT.ipynb) with a recent method that presents an alternative to Null Hypothesis Significance Testing. \n",
    "- Error analysis, which are methods to inspect the predictions made by a model, in particular, to understand the wrong predictions and propose ways to improve the model. (TO DO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dcca8f-4e2d-4045-b933-a2f69e4310ca",
   "metadata": {},
   "source": [
    "# 1. Evaluating the quality of classification models\n",
    "\n",
    "Recommendations for the evaluation of machine learning models in cheminformatics have not strayed too far from other areas of machine learning. These include calculating metrics, such as accuracy, precision and recall for classification models, which reflect how well the model is able to predict correctly the classes of data points.\n",
    "\n",
    "Model validation involves estimating the generalization error by using a model to predict unseen data points. This external dataset is often called validation and/or test set. Cross-validation is a technique that creates several dataset splits, allowing us to calculate the mean and standard deviation of the metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e82e8b-fad5-4371-86ea-27b158bdb427",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1. Calculating quality metrics for a model \n",
    "\n",
    "The most common way to evaluate your model's performance involves training it with part of the dataset, followed by using the model to predict classes for the rest of the data points (data not used in training). This usually involves creating a test set, or by the use of cross-validation.\n",
    "\n",
    "Then, classification metrics are calculated based on the predictions and the true values for the data points. Choosing the relevant metric is not always straightforward, as it can depend on the model application as well as on characteristics of the dataset, such as label imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "168aa474-cf53-4747-b4db-471d1f2de7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.855\n",
      "AUPRC: 0.840\n",
      "Balanced accuracy: 0.859\n",
      "Cohen's kappa: 0.711\n",
      "F1 score: 0.856\n",
      "MCC: 0.717\n",
      "Precision: 0.915\n",
      "Recall: 0.804\n",
      "ROC/AUC: 0.859\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split dataset randomly into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use model to predict the labels of the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auprc = average_precision_score(y_test, y_pred)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "cohens_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "print(f'AUPRC: {auprc:.3f}')\n",
    "print(f'Balanced accuracy: {balanced_accuracy:.3f}')\n",
    "print(f\"Cohen's kappa: {cohens_kappa:.3f}\")\n",
    "print(f'F1 score: {f1:.3f}')\n",
    "print(f'MCC: {mcc:.3f}')\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'Recall: {recall:.3f}')\n",
    "print(f'ROC/AUC: {roc_auc:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d703f5d0-d2ea-4579-83d7-493c6703a581",
   "metadata": {},
   "source": [
    "# 2. Statistical methods for model comparison\n",
    "\n",
    "On the previous example, we calculated metrics for a model trained using a single algorithm, logistic regression. There are several machine learning algorithms available, and each one may present different metrics for your data set.\n",
    "\n",
    "**Which model is better?** You may have asked yourself this question before. When researching the subject, we can find different answers, such as:\n",
    "\n",
    "- A model with greater generalization capacity is better\n",
    "- A simpler model is better than a more complex one (Occam's razor)\n",
    "- An interpretable model is better than a \"black box\" model\n",
    "- The model that makes the most correct predictions is the best\n",
    "- The model that makes fewer wrong predictions for the class of interest is the best\n",
    "\n",
    "And the list goes on...\n",
    "\n",
    "Note that choosing one model over another presents itself as a more complex problem.\n",
    "\n",
    "For each of the ways we use to determine the \"quality\" of our models, different approaches must be used. In this Notebook, we will deal with a specific question:\n",
    "\n",
    "*For a given a dataset, how to identify which classification algorithm yields the best model?* \n",
    "\n",
    "In fact, we might begin by asking whether they are different from each other.\n",
    "\n",
    "It is important that you make sure you are measuring exactly what you are supposed to be measuring. Therefore, this example assumes that you have already decided on the most relevant metric for your problem. Let's work with ROC/AUC for the following examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066f0a1-26a2-4d0e-a796-b9ee55f8d958",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1. Comparaing ROC/AUC for every model\n",
    "\n",
    "One approach you'll see in a lot of works involving machine learning models involves calculating one or more quality metrics, either using a test set or cross-validation, and directly comparing the calculated values.\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51f6bd4a-a54b-485d-8038-1a92d9b074e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split dataset randomly into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = [\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('Logistic Regression', LogisticRegression()),\n",
    "    ('Decision Tree', DecisionTreeClassifier())\n",
    "]\n",
    "\n",
    "# Train and evaluate models\n",
    "plt.figure(figsize=(10, 7))\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC/ROC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('AUC/ROC', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9483e2-89be-45be-9ccd-1b823d83950f",
   "metadata": {},
   "source": [
    "The general trend we see on published papers, especially those that present novel classification algorithms, is to indicate the model with the best score as \"the best model\" or \"the better performing model\".\n",
    "\n",
    "In this case, the *Random Forest* model would be chosen as the best.\n",
    "\n",
    "Note, however, that this is an **incorrect** approach.\n",
    "\n",
    "How can we guarantee that the AUC value of 0.93 for the *Random Forest* model is truly greater than the 0.92 for the logistic regression model when we know that several sources of variability exist (especially for real data)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ac40e-e580-4e3b-9220-c515099dba7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2. Confidence intervals\n",
    "\n",
    "Therefore, the next logic step is to calculate not only fixed values of the relevant metrics, but also their respective **confidence intervals**. The 95% interval is the most popular, which corresponds to 1.96 times the standard deviations (for Gaussian distributions).\n",
    "\n",
    "If we want to proceed with our comparison with due statistical rigor, we need to combine the calculation of confidence intervals with some type of **hypothesis test** to decide whether our null hypothesis (both algorithms lead to the same classification performance) will be rejected or accepted.\n",
    "\n",
    "The blog post [How to Calculate Bootstrap Confidence Intervals For Machine Learning Results in Python](https://machinelearningmastery.com/calculate-bootstrap-confidence-intervals-machine-learning-results-python/) presents a way to estimate the confidence intervals for classification metrics using the *bootstrapping* method. This  consists in performing repeated sampling with repetition, using these samples to train the model and calculating the desired metrics on the unselected samples (*out-of-bag*). See below an example adapted from the blog post:\n",
    "\n",
    "###(ADD CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdd6930-2913-4410-bbfb-df901a095b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "# from pandas import read_csv\n",
    "# from sklearn.utils import resample\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from matplotlib import pyplot\n",
    "\n",
    "# # load dataset\n",
    "# data = read_csv('pima-indians-diabetes.data.csv', header=None)\n",
    "# values = data.values\n",
    "\n",
    "# # configure bootstrap\n",
    "# n_iterations = 500\n",
    "# n_size = int(len(data) * 0.50)\n",
    "\n",
    "# # run bootstrap\n",
    "# stats = list()\n",
    "# for i in range(n_iterations):\n",
    "#     # prepare train and test sets\n",
    "#     train = resample(values, n_samples=n_size)\n",
    "#     test = numpy.array([x for x in values if x.tolist() not in train.tolist()])\n",
    "#     # fit model\n",
    "#     model = DecisionTreeClassifier()\n",
    "#     model.fit(train[:,:-1], train[:,-1])\n",
    "#     # evaluate model\n",
    "#     predictions = model.predict(test[:,:-1])\n",
    "#     score = accuracy_score(test[:,-1], predictions)\n",
    "#     print(score)\n",
    "#     stats.append(score)\n",
    "    \n",
    "# # plot scores\n",
    "# pyplot.hist(stats)\n",
    "# pyplot.show()\n",
    "\n",
    "# # confidence intervals\n",
    "# alpha = 0.95\n",
    "# p = ((1.0-alpha)/2.0) * 100\n",
    "# lower = max(0.0, numpy.percentile(stats, p))\n",
    "# p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "# upper = min(1.0, numpy.percentile(stats, p))\n",
    "# print('%.1f confidence interval %.1f%% and %.1f%%' % (alpha*100, lower*100, upper*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c86f519-c054-4717-8401-4bca0e527934",
   "metadata": {},
   "source": [
    "## 2.3. t-tests\n",
    "\n",
    "Our first choice to compare models could be to use a simple t-test, such as the Student's t-test, to compare the means of the distributions for the metrics for the two models and identify whether they are different. However, this would not be an accurate choice. For a t-test to be valid, some [conditions](https://stats.stackexchange.com/questions/250282/how-to-use-cross-validation-for-model-comparison) should be met:\n",
    "- Data must be normally distributed\n",
    "- Data must have been drawn from independent distributions (i.i.d.)\n",
    "- The variance within groups is equal within the population\n",
    "\n",
    "Sample re-use methods, such as cross-validation and bootstraping, are often presented as a method of estimating the expected test error for a model. This, however, violates the assumption that the data are independent.\n",
    "\n",
    "Furthermore, according to Blockeel (2011), estimating quality metrics using cross-validation (whether just once, such as 10-fold CV, or repeatedly, for example, 10 x 10-fold CV) has a disadvantage: when using the same data over and over again, we are calculating a value with high bias. Thus, repeated cross-validation does not allow an estimate of the true value of a metric for a model.\n",
    "\n",
    "Therefore, we need alternative approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c4e7e6-84b2-4638-81b3-b5ab8d510afa",
   "metadata": {},
   "source": [
    "## 2.4. Methods for comparing classification models: Dietterich (1998)\n",
    "\n",
    "In a 1998 paper, Dietterich proposed two methods for comparing classification models. These methods demonstrated acceptable values of Type I (incorrectly detecting a significant difference between models when it does not exist) and Type II (not detecting a difference when it exists) errors. They are presented below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d27dcc-f5e0-4f60-9e4a-c918c37b1690",
   "metadata": {},
   "source": [
    "### 2.4.1. 5×2cv paired t-test\n",
    "\n",
    "The paired t-test with 5×2-*fold* cross-validation (5×2cv paired t-test) consists in performing five cycles of 2-fold cross-validation (that is, we separate the dataset into training/test sets in a 50/50 ratio five times). Next, a modified version of the paired t-test is performed.\n",
    "\n",
    "According to the author, this method overcomes problems of the traditional paired t-test performed on cross-validation results, which are: underestimating the variance and, consequently, a high type I error.\n",
    "\n",
    "The package [mlxtend](http://rasbt.github.io/mlxtend/), authored by Sebastian Raschka, provides an implementation of this method. See the documentation [here](http://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_5x2cv/).\n",
    "\n",
    "Let's start by training two classifiers and evaluating their accuracy on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe5cd2d6-b066-402e-a3fd-c714b5fcc5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC/AUC Logistic Regression: 0.967\n",
      "ROC/AUC Decision Tree: 0.955\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from mlxtend.data import iris_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "clf1 = LogisticRegression(random_state=0)\n",
    "clf2 = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "score_lr = roc_auc_score(clf1.predict(X_test), y_test)\n",
    "score_dt = roc_auc_score(clf2.predict(X_test), y_test)\n",
    "\n",
    "print(f'ROC/AUC Logistic Regression: {score_lr:.3f}' % (score_lr*100))\n",
    "print(f'ROC/AUC Decision Tree: {score_dt:.3f}' % (score_dt*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d942b-81e2-451d-88ee-399872606916",
   "metadata": {},
   "source": [
    "Note that these values, although numerically different, may not be significantly different.\n",
    "\n",
    "Let's check if, in fact, we can say that a method is better, assuming a significance cutoff value (alpha) of 0.05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2766612-4a53-4b72-b0a3-1189c5b4af49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic: 0.000\n",
      "p value: 1.000\n"
     ]
    }
   ],
   "source": [
    "# 5x2 cv t-test\n",
    "# https://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_5x2cv/\n",
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "clf1 = LogisticRegression(random_state=0)\n",
    "clf2 = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "t, p = paired_ttest_5x2cv(estimator1=clf1,\n",
    "                          estimator2=clf2,\n",
    "                          X=X, y=y,\n",
    "                          random_seed=0)\n",
    "\n",
    "print('t statistic: %.3f' % t)\n",
    "print('p value: %.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57295b40-c6aa-4376-a65c-4e732653fcd5",
   "metadata": {},
   "source": [
    "Since the p-value is greater than the alpha value (0.05), we cannot reject the null hypothesis, and we must conclude that the performance of the two methods is not significantly different.\n",
    "\n",
    "### Comments\n",
    "\n",
    "One problem with performing this test is that the train/test splits are chosen randomly, which might not be a good idea in cheminformatics.\n",
    "\n",
    "Attention: if you are comparing the performance of more than one model, it is not correct to compare the p-values with the value 0.05 - it is necessary to apply, for example, the Bonferroni correction, which consists of dividing the alpha value by the number of models compared. So, if you are comparing 3 models, you will have to compare the p-values with 0.05/3 = 0.017. Therefore, you can only say that model A is significantly better than models B and C if the p-values for the AB and AC comparisons are less than 0.017."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a79f41-daa1-487d-b3ed-f1e11f8a7df9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3.2. McNemar's test\n",
    "\n",
    "McNemar's Test is a non-parametric statistical hypothesis test for comparing two classification models. It is a chi-squared test.\n",
    "\n",
    "This test is recommended when it is impractical to train multiple models on different subsets of the dataset (cross-validation), a common situation when working with neural networks.\n",
    "\n",
    "To perform McNemar's test, start by splitting the dataset into training and test sets. Train the two classifiers you want to compare on the training set and predict the classes for the test set (McNemar's test requires that the sets used for prediction are **identical** for both models). The results for each prediction will belong to one of the following \"classes\":\n",
    "\n",
    "- a: model 1 made a correct prediction and model 2 made a correct prediction\n",
    "- b: model 1 made a correct prediction and model 2 made an incorrect prediction\n",
    "- c: model 1 made an incorrect prediction and model 2 made a correct prediction\n",
    "- d: model 1 made an incorrect prediction and model 2 made an incorrect prediction\n",
    "\n",
    "These results can be written in the form of a table, called a **contingency table**:\n",
    "\n",
    "|   |   |\n",
    "|---|---|\n",
    "| a | b |\n",
    "| c | d |\n",
    "\n",
    "Then, the McNemar statistic is calculated using the formula:\n",
    "\n",
    "χ = (b-c)²/(b+c)\n",
    "\n",
    "There is also a corrected version of this formula, proposed by [Edwards](https://en.wikipedia.org/wiki/McNemar%27s_test):\n",
    "\n",
    "χ = (b-c-1)²/(b+c)\n",
    "\n",
    "These formulas assume that the sum of the cells used in the calculation (b+c) is at least 25. Otherwise, a modified version of the test must be used, which calculates an exact p-value using a binomial distribution.\n",
    "\n",
    "The mlextend and statsmodels packages have implementations of McNemar's test for all these cases.\n",
    "\n",
    "Note that the chi-square value can be converted to a p-value, just like for the 5x2-CV test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b8060-8502-4511-ab04-3e29ce1936d4",
   "metadata": {},
   "source": [
    "**mlextend**\n",
    "\n",
    "The `mcnemar()` function of the mlextend module takes the contingency table as an argument and returns the calculated statistic and p-value.\n",
    "\n",
    "Let's show how to use the `mcnemar_table()` function to generate the contingency table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447e87ac-eef8-4c8d-aba3-cf5bf40fbdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "# Example: mlextend\n",
    "import numpy as np\n",
    "from mlxtend.evaluate import mcnemar_table\n",
    "\n",
    "# The correct target (class) labels\n",
    "y_target = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Class labels predicted by model 1\n",
    "y_model1 = np.array([0, 1, 0, 0, 0, 1, 1, 0, 0, 0])\n",
    "\n",
    "# Class labels predicted by model 2\n",
    "y_model2 = np.array([0, 0, 1, 1, 0, 1, 1, 0, 0, 0])\n",
    "\n",
    "tb = mcnemar_table(y_target=y_target, \n",
    "                   y_model1=y_model1, \n",
    "                   y_model2=y_model2)\n",
    "\n",
    "print(tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fd519d-6270-4daf-89bf-7e2a220d0294",
   "metadata": {},
   "source": [
    "After calculating the contingency table, we can calculate the statistics and p-values\n",
    "\n",
    "Three options are available for the `mcnemar()` function, depending on the arguments used:\n",
    "\n",
    "1. exact=True: Calculates an exact p-value using a binomial distribution. Recommended when b + c < 25\n",
    "2. exact=False, corrected=True: uses the Edwards correction\n",
    "3. exact=False, corrected=False: calculates the value without correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc68250-27c1-4056-b4c5-bea6f6fe78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "# Mcnemar's test - choose the appropriate version\n",
    "chi2, p = mcnemar(ary=tb, exact=True)\n",
    "# chi2, p = mcnemar(ary=tb, exact=False, corrected=False)\n",
    "# chi2, p = mcnemar(ary=tb, exact=False, corrected=True)\n",
    "\n",
    "print('chi-squared:', chi2)\n",
    "print('p-value:', p)\n",
    "\n",
    "# Interpret p-value\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "     print('Same error proportions (we do not reject H0, the models are not different)')\n",
    "else:\n",
    "     print('Different error proportions (we reject H0, the models are different)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b790c22-e005-4394-a18c-1107acfc27cb",
   "metadata": {},
   "source": [
    "**statsmodels**\n",
    "\n",
    "The `mcnemar()` function in the statsmodels module takes the contingency table as an argument and returns the calculated statistic and p-value.\n",
    "\n",
    "Three options are available, depending on the arguments used:\n",
    "\n",
    "1. exact=True: Calculates an exact p-value using a binomial distribution. Recommended when b + c < 25\n",
    "2. exact=False, correction=True: uses the Edwards correction\n",
    "3. exact=False, correction=False: calculates the value without the correction\n",
    "\n",
    "I set up a contingency table with random values. Since b+c > 25, we will use the corrected version of McNemar's test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ec6e2d-f465-4a61-bdd8-92fc1eb07ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: statsmodels\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "table = [[400, 25],\n",
    "         [13, 300]]\n",
    "\n",
    "# Mcnemar's test\n",
    "# result = mcnemar(table, exact=True)\n",
    "result = mcnemar(table, exact=False, correction=True)\n",
    "# result = mcnemar(table, exact=False, correction=False)\n",
    "\n",
    "# Show results\n",
    "print('statistic=%.3f, p-value=%.3f' % (result.statistic, result.pvalue))\n",
    "\n",
    "# Interpret p-value\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "     print('Same error proportions (we do not reject H0, the models are not different)')\n",
    "else:\n",
    "     print('Different error proportions (we reject H0, the models are different)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bbacc3-dbb5-4431-9298-f911d4ccb7f9",
   "metadata": {},
   "source": [
    "In this [*blog post*](http://practicalcheinformatics.blogspot.com/2020/05/some-thoughts-on-comparing.html), the author performs the test 10 times using cross validation (9:1) and calculates the distribution and confidence intervals of the p-values, and regards as different the methods for which median is below the corrected alpha value (0.05/3, in the example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4afe2-5db4-4772-bdef-e478d84064d4",
   "metadata": {},
   "source": [
    "## 2.4. Methods to compare classification models: Advances\n",
    "\n",
    "Blockeel (2011) identifica em seu artigo *On Estimating Model Accuracy with Repeated Cross-Validation* mais três trabalhos que propõem métodos para comparar algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86499db-107a-40e8-a085-113edfad2b5d",
   "metadata": {},
   "source": [
    "### 2.4.1. 5×2cv F-test\n",
    "\n",
    "Alpaydin (1999) improved the 5×2cv t-test by demonstrating that a 5×2cv F-test would be more robust, with lower type I error and greater statistical power.\n",
    "\n",
    "This test is also available on [mlextend](https://rasbt.github.io/mlxtend/user_guide/evaluate/combined_ftest_5x2cv/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e86437-c2c5-4d6e-a482-3068242069a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5x2 cv F-test\n",
    "# https://rasbt.github.io/mlxtend/user_guide/evaluate/combined_ftest_5x2cv/\n",
    "from mlxtend.evaluate import combined_ftest_5x2cv\n",
    "\n",
    "f, p = combined_ftest_5x2cv(estimator1=knn_classifier,\n",
    "                            estimator2=et_classifier,\n",
    "                            X=X_train, y=y_train,\n",
    "                            random_seed=123)\n",
    "\n",
    "print('F statistic: %.3f' % f)\n",
    "print('p-value: %.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ef45a9-f7ae-4a3c-a66e-f0226f5a7549",
   "metadata": {},
   "source": [
    "### 2.4.2. 10×10cv with calibrated degrees of freedom\n",
    "\n",
    "Bouckaert (2003) claims that 5×2cv, methods that involve resampling and 10-fold cv suffer from **low replicability**, and that the reuse of data causes the estimated variance to be smaller than the real variation, i.e., the effective degrees of freedom are much lower than theoretically expected, which increases Type I error.\n",
    "\n",
    "The alternative presented in this work consists of using the 10 time repeated 10 fold cross validation (10×10cv) test and empirically calibrating the effective degrees of freedom.\n",
    "\n",
    "In other words, the authors suggest multiplying the variance by a coefficient, based on the [correction proposed by Nadeau and Bengio](https://stats.stackexchange.com/questions/217466/for-model-selection-comparison-what-kind-of-test-should-i-use), and reducing the degrees of freedom for the 10×10cv from 99 to 10. Using 10×10cv should also improve replicability. \n",
    "\n",
    "[Check out this e-mail exchange between Bouckaert and Dietterich](https://wekalist.scms.waikato.ac.narkive.com/O5jqNlHe/10-by-10-way-cross-validation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b7fa2bb-97c3-4df4-8a26-e423e48b4e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "X, y = make_classification(n_samples=100, n_features=20, n_classes=2, random_state=0)\n",
    "\n",
    "# Create 10x10 cv object\n",
    "# Modify these for a different number of splits or repeats\n",
    "n_splits=10\n",
    "n_repeats=10\n",
    "cv = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=0)\n",
    "# Use RepeatedStratifiedKFold for unbalanced datasets?\n",
    "\n",
    "# Models\n",
    "clf1 = LogisticRegression(random_state=0)\n",
    "clf2 = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# We will \"use all data\", as explained in Bouckaert's e-mail,\n",
    "# using ROC/AUC instead of accuracy\n",
    "scores1 = cross_val_score(clf1, X, y, scoring='roc_auc', cv=cv)\n",
    "scores2 = cross_val_score(clf2, X, y, scoring='roc_auc', cv=cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c613983-cfdc-40d3-aed2-4e843bf07d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the corrected t-statistic\n",
    "\n",
    "# Factors\n",
    "n_samples = n_splits*n_repeats\n",
    "df = 10  # calibrated value determined for the 10x10 cv \n",
    "diff_scores = scores1 - scores2\n",
    "mean_diff_scores = diff_scores.mean()\n",
    "var_diff_scores = diff_scores.var()\n",
    "\n",
    "# Correction term for the variance\n",
    "n1 = 1 - 1/n_splits  # fraction of the data used for training\n",
    "n2 = 1/n_splits # fraction of the data used for testing\n",
    "correction_factor_var = (1/n_samples) + (n2/n1)\n",
    "\n",
    "# Corrected variance\n",
    "corrected_var = var_diff_scores * correction_factor_var\n",
    "\n",
    "# Corrected t-statistic\n",
    "t = (mean_diff_scores * n_samples) / ( np.sqrt(corrected_var) / np.sqrt(df+1) )\n",
    "print(f'10x10 cv t-statistic: {t:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28be830-4818-43b5-ae9f-2d0108315b74",
   "metadata": {},
   "source": [
    "### 2.4.3. Other works\n",
    "\n",
    "The two following papers discuss methods for comparing the general performance of algorithms, and not the comparison of trained models (predictors trained on a fixed training set), which is the aim of this Notebook. Therefore, I will comment on them briefly.\n",
    "\n",
    "Nadeau and Bengio (2000) propose the corrected resampled t-test that takes into account the variability due to the choice of training set, and not only that due to the test examples. [Bouckaert and Frank](https://www.cs.waikato.ac.nz/~eibe/pubs/bouckaert_and_frank.pdf) also investigated the replicability of machine learning experiments and found the 5×2cv t-test dissatisfactory, opting for the corrected resampled t-test. \n",
    "\n",
    "This version of the corrected resampled t-test has apparently been implemented in Python [in this link](https://gist.github.com/jensdebruijn/13e8eeda85eb8644ac2a4ac4c3b8e732), but use with caution, because the comments indicate that there might be a mistake in the code.\n",
    "\n",
    "Demšar (2006) deals with cases in which we want to compare classifiers trained on several datasets. For this, tests for multiple comparisons must be used.\n",
    "\n",
    "This is a common scenario in the development of new classifiers, when we wish to compare their performance for different prediction tasks. These datasets, often selected by the scientific community especially for comparisons between models, are commonly called **benchmarks**.\n",
    "\n",
    "To those interested in this area, a quote from the paper abstract might indicate a possible starting point:\n",
    "\n",
    "> we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD (critical difference) diagrams\n",
    "\n",
    "[But keep in mind that](https://machinelearningmastery.com/statistical-significance-tests-for-comparing-machine-learning-algorithms/):\n",
    "\n",
    "> Although the test is nonparametric, it still assumes that the observations within each sample are independent (e.g. iid), and using k-fold cross-validation would create dependent samples and violate this assumption.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af910da-05a1-4ae5-876d-8dd409a9ee22",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.5. Beyond hypothesis testing\n",
    "\n",
    "### 2.5.1. Estimation statistics\n",
    "\n",
    "Estimation statistics is the group of methods that focus on the estimation of effect sizes (point estimates) and their confidence intervals (precision estimates). \n",
    "\n",
    "Unlike hypothesis tests, they indicate not only whether two samples are different, but also the direction of the difference.\n",
    "\n",
    "These methods are often viewed as a complement to hypothesis tests rather than a replacement to them, although some have claimed that estimation methods should be preferred. For instance: [Estimation statistics should replace significance testing](https://www.nature.com/articles/nmeth.3729)\n",
    "\n",
    "---\n",
    "Long discussion, maybe make another notebook...\n",
    "\n",
    "See:\n",
    "- https://machinelearningmastery.com/estimation-statistics-for-machine-learning/\n",
    "- https://machinelearningmastery.com/statistical-significance-tests-for-comparing-machine-learning-algorithms/\n",
    "- https://en.wikipedia.org/wiki/Estimation_statistics\n",
    "- https://arxiv.org/pdf/2308.09112.pdf\n",
    "\n",
    "Update: I made a [notebook](https://github.com/rflameiro/projects/blob/main/R_REACT.ipynb) showing how to use the REACT Framework (R code)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8950c-9cfb-44bf-a708-2cce23cc9933",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Is it all worthwhile?\n",
    "\n",
    "In \"Classifier Technology and the Illusion of Progress\" (hereon Cl tech), David J. Hand discusses how simple models often provide the same performance as more complex classifiers. We will discuss some of these points in the context of cheminformatics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd483f5b-e39c-49b5-be8f-8116cd6b9ced",
   "metadata": {},
   "source": [
    "## 3.1. Bayes error rate\n",
    "\n",
    "In summary, the BER is the lowest possible error rate (which is 1 - accuracy) any classifier can achieve on a fixed probability distribution. \n",
    "\n",
    "In Cl tech it is claimed that algorithms slightly more complex than linear discriminant analysis might already be at the limit of the Bayes error rate. Therefore, highly complex models, such as neural networks, operate in a diminishing gains situation and are not likely to improve our predictive ability significantly.\n",
    "\n",
    "Understanding how close your baseline performance is to the BER will tell you how much more improvement you can get by using more complex models. Estimating the BER can also help us understand the true difference in performance of different classifiers.\n",
    "\n",
    "Since this Notebook is already too long, I decided to make [another one discussing the Bayes Error Rate (BER) and its estimation](https://github.com/rflameiro/projects/blob/main/Bayes_Error_Rate_Estimation.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb930cd8-4a19-469f-a10d-f0e8189ce946",
   "metadata": {},
   "source": [
    "## 3.2 Should we stick to simple models?\n",
    "\n",
    "The principle of parsimony suggests that it is better to stick to simple models. This feels even more appropriate when statistical analyses seem to point us that the performance of novel methods might not be significantly different from a Random Forest baseline, for instance. \n",
    "\n",
    "However, the winning entries to several chemical property prediction competitions in Kaggle seem to be dominated by neural networks, even when molecular descriptors are provided in tabular format (a known Achilles' heel of the neural network architecture). See, for instance, \n",
    "\n",
    "> Amit Kulkarni, BobS, joycenv, Merck_GSC. (2012). Merck Molecular Activity Challenge. Kaggle. https://kaggle.com/competitions/MerckActivity. There was a blog post about the winning entry, which was an MLP, but the link does not work anymore. The authors published some papers after the competition, such as [Deep Neural Nets as a Method for Quantitative Structure–Activity Relationships](https://pubs.acs.org/doi/10.1021/ci500747n).\n",
    "\n",
    "> Addison Howard, inversion, Lars Bratholm. (2019). Predicting Molecular Properties. Kaggle. https://kaggle.com/competitions/champs-scalar-coupling. And the winning entry: [#1 Solution - hybrid](https://www.kaggle.com/c/champs-scalar-coupling/discussion/106575), a GNN (graph transformer).\n",
    "\n",
    "> Andrea Zaliani, Jing Tang, Julio Martin, Robert Harmel, Wenyu Wang. (2022). 1st EUOS/SLAS Joint Challenge: Compound Solubility . Kaggle. https://kaggle.com/competitions/euos-slas. And the winning entry: [openOCHEM](https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/646b91ecccabde9f6e2fc4b5/original/open-ochem-consensus-model-wins-kaggle-first-euos-slas-joint-compound-solubility-challenge.pdf), a GNN.\n",
    "\n",
    "Check out this comment by Derek Lowe on [Did Kaggle Predict Drug Candidate Activities? Or Not?](https://www.science.org/content/blog-post/did-kaggle-predict-drug-candidate-activities-or-not):\n",
    ">  All of these algorithm-hunting methods can face a crucial dependence on the training sets used, and their relations to the real data. Never was \"Garbage In, Garbage Out\" more appropriate. If you feed in numbers that are intrinsically too well-behaved, you can emerge with a set of rules that look rock-solid, but will take ou completely off into the weeds when faced with a more real-world situation. And if you go to the other extreme, starting with wooly multi-binding-mode SAR with a lot of outliers and singletons in it, you can end up fitting equations to noise and fantasies. That does no one any good, either.\n",
    "\n",
    "It also appears that [Big Pharma](https://www.sciencedirect.com/science/article/pii/S1359644620302609#fig0010) has  been replacing traditional methods, such as PLS, by random forests and neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723a99f2-a448-4b7e-bac7-4b93194518c1",
   "metadata": {},
   "source": [
    "## 3.3. Data in medicinal chemistry\n",
    "\n",
    "After all this discussion, we must now look at the following problem: the data we usually work with in cheminformatics are not of the same type as data historically used in machine learning (statistical learning) works, such as texts or images.\n",
    "\n",
    "This raises a series of problems, which I briefly describe below:\n",
    "\n",
    "**Problem #1: Data in medicinal chemistry is not randomly drawn**\n",
    "\n",
    "According to Cl Tech, \n",
    "> Intrinsic to the classical supervised classification paradigm is the assumption that the data in the design set are randomly drawn from the same distribution as the points to be classified in the future\". \n",
    " \n",
    "In fact, chemical structure data sets are not, in general, constructed from randomly and independently selected data. This is even clearer in medicinal chemistry, as there is a bias, for example, towards scaffolds with a greater chance of activity towards the desired target, drug-likeness properties, or commercially available compounds (in general, easier to synthesize).\n",
    "\n",
    "The paper [Reliable estimation of prediction errors for QSAR models under model uncertainty using double cross-validation](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-014-0047-1) adds:\n",
    "> When validation objects are not independent from those used to train the model, the process is also subject to model selection bias, when a suboptimal model presents the best metrics.\n",
    "\n",
    "This example from Cl tech is also interesting, especially in the context of virtual screening:\n",
    "> one area that involves sample selectivity in classification problems... arises in the retail financial services industry... the aim is to predict, for example, on the basis of application and other background variables, whether or not an applicant is likely to be a good customer. Those expected to be good are accepted, and those expected to be bad are rejected. For those that have been accepted, we subsequently discover their true good or bad class. For the rejected applicants, however, we never know whether they are good or bad. The consequence is that the resulting sample is distorted as a sample from the population of applicants, which is our real interest for the future. Measuring the performance or attempting to build an improved classification rule using those individuals for which we do know the true class (which is needed for supervised classification) has the potential to be highly misleading for the overall applicant population. \n",
    "\n",
    "**Problem #2: Present data is noisy and future data might not look like present data**\n",
    "\n",
    "Therefore, it looks like we shouldn't worry too much about getting that 5% improvement in metrics with the data we have available, since the noise is likely greater than that, and future data is also likely to drift away from it (increasing uncertainty).\n",
    "\n",
    "**Problem #3: Arbitrary classification thresholds**\n",
    "\n",
    "The activity cutoff that defines an active compound can change over time. For instance, an active compound at the beginning of a lead discovery process may be something as weak as an 80% inhibition, which will evolve towards measurable pKi values from high micromolar to low nanomolar.\n",
    "\n",
    "**Problem #4: Picking the wrong metric for your problem**\n",
    "\n",
    "In Cl Tech it is suggested that choosing equal misclassification costs (putting the same weight on both classes) may be more often inappropriate than appropriate.\n",
    "\n",
    "> All too often, however, there is a mismatch between the criterion used to choose the model, the criterion used to evaluate its performance, and the criterion which actually matters in real application. \n",
    "\n",
    "For instance, for a model that will be used in a virtual screening context, the [recall in the 1% of top-ranked compounds](https://www.sciencedirect.com/science/article/pii/S2667318522000265) might be a more appropriate metric than ROC/AUC.\n",
    "\n",
    "**Problem #5: Memorization**\n",
    "\n",
    "Many works deal with the concept of bias in benchmarks for molecular classification problems. These papers seem to point towards a trend of memorization (overfitting) as a significant factor for \"improved\" metrics. See, for instance: [Most Ligand-Based Classification Benchmarks Reward Memorization Rather than Generalization](https://pubs.acs.org/doi/10.1021/acs.jcim.7b00403).\n",
    "\n",
    "**Problem #6: Complex models**\n",
    "\n",
    "In addition to all that has been discussed, works in cheminformatics are increasingly exploring more complex algorithms, such as neural networks, which can make the use of resampling and cross-validation methods unfeasible. This adds another hindrance in applying the methods discussed in previous sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b2509d-fe43-4ae8-8660-dbfeffcc854d",
   "metadata": {},
   "source": [
    "## 3.4 A final suggestion\n",
    "\n",
    "Therefore, a reasonable proposal for comparing models in medicinal chemistry seems to be the following:\n",
    "- Separate a test set in order to avoid data leakage and maximize the chance of actually quantifying the generalization of the models. Consider using a debiasing approach, such as MUV or AVE, to create a \"challenging\" test set (but beware of its limitations, such as decreased model performance).\n",
    "- Determine the quality metrics most relevant to your problem.\n",
    "- Use y-randomization to validate your model.\n",
    "- Use the training set to calculate these quality metrics and their confidence intervals, using *bootstrapping* or cross-validation. It could be a good idea to use scaffold split or the SIMPD approach.\n",
    "- Perform the McNemar test to compare the final model with a strong baseline, such as Random Forest, using the \"challenging\" test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eea9f2-1a70-4326-9f56-d4817d37a4cc",
   "metadata": {},
   "source": [
    "# 4. Beyond model comparison\n",
    "\n",
    "One thing that might concern you after all this discussion is: what to do if your model is not significantly better than a Random Forest? You might find comfort in thse words by Blockeel about methods for comparing classification mdoels:\n",
    "\n",
    "> While these methods are carefully designed, and are shown to improve upon previous methods in a number of ways, they suffer from the same risk as previous methods, namely that, the more complex a method is, the higher the risk that researchers will use it incorrectly, or interpret the result incorrectly.\n",
    "\n",
    "Demšar also concludes his paper stating:\n",
    "\n",
    "> statistical tests should not be the deciding factor for or against publishing the work. Other merits of the proposed algorithm that are beyond the grasp of statistical testing should also be considered and possibly even favoured over pure improvements in predictive power\n",
    "\n",
    "However, it is not stated what these \"other merits\" are. \n",
    "\n",
    "Advantages that one model may present over another:\n",
    "- Even an incremental increase can be relevant, for instance, if it leads to an improved hit rate in virtual screening\n",
    "- Better interpretability\n",
    "- Improved ability to predict the class of interest\n",
    "- Better generalization capacity (lack of generalization can be a problem with models trained on molecular *fingerprints* - [see, for instance](https://chemrxiv.org/engage/chemrxiv/article-details/64c012a1b053dad33ae21932))\n",
    "- A new algorithm that deals better with activities cliffs, which are overall a small part of a dataset, might not be statistically different from a Random Forest model and still be claimed as an advancement.\n",
    "\n",
    "In summary, reducing a model to a distribution of scores or a significance statistic, while useful in some cases, is not guaranteed to give you the full picture.\n",
    "\n",
    "Additional steps that you can take when creating a better model:\n",
    "\n",
    "- Use interpretability methods to try to rationalize the predictions (these are not guaranteed to be accurate, especially when predicting compounds used during training. See, for instance, [this preprint](https://proceedings.mlr.press/v206/jethani23a/jethani23a.pdf)). \n",
    "- Inspect wrong predictions closely (error analysis), and see how you can improve your dataset. Answer, for instance: out of the misclassified samples, how many represent unique scaffolds? How are the wrong predictions distributed in terms of distance to the nearest neighbor in the training set? How are the wrong predictions distributed in terms of the most important features in your model?\n",
    "- Define accurately the domain of applicabililty of your final model to understand the limitations of its predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b68fdd-213e-436c-83fe-855ecaf48c5d",
   "metadata": {},
   "source": [
    "# 5. Sources\n",
    "\n",
    "## Books\n",
    "\n",
    "[The Elements of Statistical Learning. Cap. 7 - Model Assessment and Selection](https://hastie.su.domains/Papers/ESLII.pdf)\n",
    "\n",
    "## Blogs\n",
    "\n",
    "### Model comparison\n",
    "\n",
    "[Machine Learning Mastery: Confidence Intervals for Machine Learning](https://machinelearningmastery.com/confidence-intervals-for-machine-learning/)\n",
    "\n",
    "[Machine Learning Mastery: How to Calculate McNemar’s Test to Compare Two Machine Learning Classifiers](https://machinelearningmastery.com/mcnemars-test-for-machine-learning/)\n",
    "\n",
    "[Machine Learning Mastery: Statistical Significance Tests for Comparing Machine Learning Algorithms](https://machinelearningmastery.com/statistical-significance-tests-for-comparing-machine-learning-algorithms/)\n",
    "\n",
    "[Practical Cheminformatics: Some Thoughts on Comparing Classification Models](http://practicalcheminformatics.blogspot.com/2020/05/some-thoughts-on-comparing.html)\n",
    "\n",
    "[Pat Walters' Github: Comparing Classification Models](https://colab.research.google.com/github/PatWalters/practical_cheminformatics_tutorials/blob/main/ml_models/comparing_classification_models.ipynb#scrollTo=ZFPXBOPgmSbN)\n",
    "\n",
    "[Stack Exchange: For model selection/comparison, what kind of test should I use?](https://stats.stackexchange.com/questions/217466/for-model-selection-comparison-what-kind-of-test-should-i-use)\n",
    "\n",
    "## Papers\n",
    "\n",
    "[Walters (2022). Comparing classification models—a practical tutorial](https://doi.org/10.1007/s10822-021-00417-2). Suggests using McNemar test to compare classifiers in cheminformatics, based on the work of Dietterich (1998).\n",
    "\n",
    "[Dietterich (1998). Approximate Statistical Tests for Comparing Supervised Classification Learning Algorithms](https://sci2s.ugr.es/keel/pdf/algorithm/articulo/dietterich1998.pdf). Suggests using 5x2cv t-test and McNemar to compare classifiers.\n",
    "\n",
    "[Blockeel (2011). On Estimating Model Accuracy with Repeated Cross-Validation](https://lirias.kuleuven.be/1655861). Shows that, due to the high bias resulting from using the same data to calculate metrics, repeated cross-validation does not allow an estimate of the true quality of a model. Suggests the following articles for model comparison methods:\n",
    "\n",
    "- [Alpaydin (1999). Combined 5 × 2 cv F Test for Comparing Supervised Classification Learning Algorithms](https://www.cmpe.boun.edu.tr/~ethem/files/papers/NC110804.PDF). 5x2cv F-test as a more robust alternative to the 5x2cv t-test.\n",
    "\n",
    "- [Bouckaert (2001). Choosing between two learning algorithms based on calibrated tests](https://www.cs.waikato.ac.nz/~ml/publications/2003/bouckaert-calibrated-tests.pdf)\n",
    "\n",
    "- [Demsar (2006). Statistical Comparisons of Classifiers over Multiple Data Sets](https://www.jmlr.org/papers/volume7/demsar06a/demsar06a.pdf). More relevant for works that compare different classifiers on different data sets (usually, when new algorithms or new forms of molecular representation are proposed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab09977-32f6-45e7-ab82-b613c227e2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "890afc41-192f-47d9-9dc7-8a9e695decd8",
   "metadata": {},
   "source": [
    "Regression\n",
    "\n",
    "metrics: R², MAE, MSE for regression problems\n",
    "\n",
    "For regression models, the paper [Reliable estimation of prediction errors for QSAR models under model uncertainty using double cross-validation](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-014-0047-1) showed that double cross-validation wielded reliable and unbiased estimates of prediction errors, providing a more realistic picture of model quality compared to using a single test set. Note, however, that the authors evaluated algorithms that are not so much in vogue these days (multiple linear regression and PLS). It will be discussed below that (repeated) cross-validation for cheminformatics datasets might not always be the best choice.\n",
    "\n",
    "https://jcheminf.biomedcentral.com/articles/10.1186/s13321-023-00751-7#Sec6\n",
    "\n",
    "P-values of one-tailed Wilcoxon tests between the best models trained on each representation. The value in i-th row and j-th column corresponds to the alternative hypothesis saying that the median squared error of i-th representation is greater than the median of j-th representation (superior representations have darker columns, and inferior ones have darker rows). The darkest cells are statistically significant with Bonferroni correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2144185-c506-4047-8b59-69b1f30d622d",
   "metadata": {},
   "source": [
    "A systematic study of key elements underlying molecular property prediction\n",
    "\n",
    "Recently, Bender et al.75 proposed a set of evaluation guidelines for machine learning tools, covering appropriate comparison methods and evaluation metrics, among other essential aspects. 75. \n",
    "\n",
    "Since we observed that the distribution of each performance metric is skewed together with heteroscedasticity (Supplementary Figs. 14, 15, 21, 22), Mann–Whitney U test was used to calculate the pairwise significance. The significant level is set as the two-sided p value < 0.05\n",
    "\n",
    "uses Mann–Whitney U test, but does not seem to correct for multiple comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8618cee2-bd8c-481e-a5c9-73803594716a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
