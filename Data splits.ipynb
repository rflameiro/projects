{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a82f4363-81e2-4549-b4fb-e42da4ec09c0",
   "metadata": {},
   "source": [
    "# Data splitting in model validation\n",
    "\n",
    "Model validation involves assessing the quality of the predictions on unseen data, that is, data not used during training.\n",
    "\n",
    "Classically in statistical learning, this \"prediction set\", also called \"validation set\" or \"test set\" according to context, is sampled **randomly** from all data available. This is called a random data split.\n",
    "\n",
    "See, for instance, the many options available in [scikit learn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection), which can sample data randomly or take into account stratification of target values, as well as allow the use of more than one data split (cross-validation).\n",
    "\n",
    "The metrics obtained from such random splits might be predictive of model performance for tasks such as digit recognition, for which not much data drift is expected, that is, future data is likely to be similar to data available during training. \n",
    "\n",
    "This, however, is not usually the case for cheminformatics datasets, especially when, e.g., we are trying to identify novel hits for a target of interest. Random test sets tend to be \"easier\" to predict than actual future data, which means that any quality metrics calculated will not reflect true model performance.  Alternative approaches are needed to account for a possible change in the chemical space of new compounds.\n",
    "\n",
    "Several alternative splitting methods have been developed. [Deepchem](https://github.com/deepchem/deepchem/tree/master), a Python package with molecular machine learning tools, implements some of the most used ones.\n",
    "\n",
    "To use DeepChem locally on a Jupyter Notebook, follow the instructions on: https://deepchem.readthedocs.io/en/latest/get_started/installation.html#jupyter-notebook. Then, install Jupyter using:\n",
    "\n",
    "`pip install notebook`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af94040e-8fd3-42a0-8aa9-d85ee1d41316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Pytorch utilities, missing a dependency. No module named 'torch'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This module requires PyTorch to be installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for AvgIpc. Feature removed!\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'torch'\n",
      "No module named 'torch'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.7.2.dev'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "\n",
    "dc.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1adf59-9f83-4e12-bd3a-c817a4305938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "import pandas as pd \n",
    "\n",
    "# SMILES and target\n",
    "url = 'https://raw.githubusercontent.com/rflameiro/Python_e_Quiminformatica/main/datasets/BBBP_curated.csv'\n",
    "df_smi = pd.read_csv(url, sep=\";\", index_col=False)\n",
    "# Fingerprints and target\n",
    "url = 'https://raw.githubusercontent.com/rflameiro/Python_e_Quiminformatica/main/datasets/BBBP_morganFP_1024_radius3.csv'\n",
    "df_fp = pd.read_csv(url, sep=\";\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bacc276c-6980-4571-9f99-f9ca65133b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['std_smiles', 'p_np'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d92e2e-7064-49af-9cc0-993348ef90ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp[\"ids\"] = df_smi[\"std_smiles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20efc39c-cd1b-4963-8a39-54c1e4617360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>morgan_bit_0</th>\n",
       "      <th>morgan_bit_1</th>\n",
       "      <th>morgan_bit_2</th>\n",
       "      <th>morgan_bit_3</th>\n",
       "      <th>morgan_bit_4</th>\n",
       "      <th>morgan_bit_5</th>\n",
       "      <th>morgan_bit_6</th>\n",
       "      <th>morgan_bit_7</th>\n",
       "      <th>morgan_bit_8</th>\n",
       "      <th>morgan_bit_9</th>\n",
       "      <th>...</th>\n",
       "      <th>morgan_bit_1016</th>\n",
       "      <th>morgan_bit_1017</th>\n",
       "      <th>morgan_bit_1018</th>\n",
       "      <th>morgan_bit_1019</th>\n",
       "      <th>morgan_bit_1020</th>\n",
       "      <th>morgan_bit_1021</th>\n",
       "      <th>morgan_bit_1022</th>\n",
       "      <th>morgan_bit_1023</th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cc1onc(-c2ccccc2Cl)c1C(=O)NC1C(=O)N2C1SC(C)(C)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CCN1CCN(C(=O)NC(C(=O)NC2C(=O)N3C(C(=O)O)=C(CSc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CN(C)C1C(=O)C(C(=O)NCN2CCCC2)C(=O)[C@@]2(O)C(=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cc1nccn1CC1CCc2c(C1=O)c1ccccc1n2C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>COc1ccc([C@@H]2Sc3ccccc3N(CCN(C)C)C(=O)C2OC(C)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   morgan_bit_0  morgan_bit_1  morgan_bit_2  morgan_bit_3  morgan_bit_4  \\\n",
       "0             0             1             0             0             0   \n",
       "1             0             1             1             0             0   \n",
       "2             0             0             0             0             1   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   morgan_bit_5  morgan_bit_6  morgan_bit_7  morgan_bit_8  morgan_bit_9  ...  \\\n",
       "0             1             0             0             0             0  ...   \n",
       "1             1             0             0             0             0  ...   \n",
       "2             0             0             0             0             0  ...   \n",
       "3             1             0             0             0             0  ...   \n",
       "4             1             0             1             0             0  ...   \n",
       "\n",
       "   morgan_bit_1016  morgan_bit_1017  morgan_bit_1018  morgan_bit_1019  \\\n",
       "0                0                0                0                1   \n",
       "1                0                1                0                1   \n",
       "2                0                0                0                1   \n",
       "3                0                0                0                1   \n",
       "4                0                1                0                1   \n",
       "\n",
       "   morgan_bit_1020  morgan_bit_1021  morgan_bit_1022  morgan_bit_1023  target  \\\n",
       "0                0                0                0                0       1   \n",
       "1                0                0                0                0       1   \n",
       "2                0                0                0                0       1   \n",
       "3                0                1                0                0       1   \n",
       "4                0                0                0                0       1   \n",
       "\n",
       "                                                 ids  \n",
       "0  Cc1onc(-c2ccccc2Cl)c1C(=O)NC1C(=O)N2C1SC(C)(C)...  \n",
       "1  CCN1CCN(C(=O)NC(C(=O)NC2C(=O)N3C(C(=O)O)=C(CSc...  \n",
       "2  CN(C)C1C(=O)C(C(=O)NCN2CCCC2)C(=O)[C@@]2(O)C(=...  \n",
       "3                  Cc1nccn1CC1CCc2c(C1=O)c1ccccc1n2C  \n",
       "4  COc1ccc([C@@H]2Sc3ccccc3N(CCN(C)C)C(=O)C2OC(C)...  \n",
       "\n",
       "[5 rows x 1026 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0852a12c-2f72-4e1a-a502-d1c3085b5415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1934, 2)\n",
      "(1934, 1026)\n"
     ]
    }
   ],
   "source": [
    "print(df_smi.shape)\n",
    "print(df_fp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ab2f2b-c2f7-466e-9af4-d11461fd2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Deepchem dataset object with SMILES as the ids field\n",
    "X_cols = df_fp.columns.to_list()[:-2]\n",
    "dataset = dc.data.NumpyDataset.from_dataframe(df_fp, \n",
    "                                              X=X_cols, \n",
    "                                              y=\"target\", \n",
    "                                              ids=\"ids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e910e-894d-49aa-814e-01e7abac335c",
   "metadata": {},
   "source": [
    "# Random split\n",
    "\n",
    "Deepchem has the option to create a random split, which we will use to compare with other splitting methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b40f6ab8-40cb-41a3-aeb0-46897ad41c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "\n",
    "splitter = dc.splits.RandomSplitter()\n",
    "train_random, test_random = splitter.train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f78b945b-d3e4-4373-bf70-4af6c6a8f888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1547, 1024), (1547, 1), (1547, 0), (1547,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_random.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca90181-8a2d-4a8c-9e49-1b542374ac5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((387, 1024), (387, 1), (387, 0), (387,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_random.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4313b525-72e4-41fb-ade7-fa4b736dbf0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547, 1026)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can convert them back to pandas DataFrames\n",
    "# Note that the labels of the X columns are replaced by X1, X2...\n",
    "pandas_random = train_random.to_dataframe()\n",
    "pandas_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1025cb6-e01c-4cee-9df3-94e91c2537a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X1017</th>\n",
       "      <th>X1018</th>\n",
       "      <th>X1019</th>\n",
       "      <th>X1020</th>\n",
       "      <th>X1021</th>\n",
       "      <th>X1022</th>\n",
       "      <th>X1023</th>\n",
       "      <th>X1024</th>\n",
       "      <th>y</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CC(=O)OCC1=C(C(=O)O)N2C(=O)C(NC(=O)CC#N)C2SC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>O=C(Nc1ccccc1)OCC1(COC(=O)Nc2ccccc2)CCCC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CN1CCC(=C2c3c(cccc3)Sc3c2cccc3)CC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>O=[N+]([O-])C1=CC=NC1NCCSCc1ncccc1Br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CN(C)c1nc(O)c(-c2ccccc2)o1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  X3  X4  X5  X6  X7  X8  X9  X10  ...  X1017  X1018  X1019  X1020  \\\n",
       "0   0   0   0   0   0   1   0   0   0    0  ...      0      1      0      1   \n",
       "1   0   0   0   0   1   0   0   0   0    0  ...      0      0      0      0   \n",
       "2   0   0   0   0   0   0   0   0   0    0  ...      0      0      0      0   \n",
       "3   0   0   0   0   0   0   0   0   0    0  ...      0      1      0      1   \n",
       "4   0   0   0   0   0   0   0   0   0    0  ...      0      0      0      0   \n",
       "\n",
       "   X1021  X1022  X1023  X1024  y  \\\n",
       "0      0      0      0      0  0   \n",
       "1      0      0      0      0  1   \n",
       "2      1      1      0      0  1   \n",
       "3      0      0      0      0  1   \n",
       "4      0      0      0      0  1   \n",
       "\n",
       "                                             ids  \n",
       "0  CC(=O)OCC1=C(C(=O)O)N2C(=O)C(NC(=O)CC#N)C2SC1  \n",
       "1      O=C(Nc1ccccc1)OCC1(COC(=O)Nc2ccccc2)CCCC1  \n",
       "2             CN1CCC(=C2c3c(cccc3)Sc3c2cccc3)CC1  \n",
       "3           O=[N+]([O-])C1=CC=NC1NCCSCc1ncccc1Br  \n",
       "4                     CN(C)c1nc(O)c(-c2ccccc2)o1  \n",
       "\n",
       "[5 rows x 1026 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_random.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "369a1741-5eb7-4889-b126-08aead4b2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternativaly, export .csv\n",
    "# train_random.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461bfb93-2602-44e5-bdd2-2d6ce425e488",
   "metadata": {},
   "source": [
    "# Cluster split\n",
    "\n",
    "Two versions of this split exist:\n",
    "\n",
    "The first requires using a clustering algorithms that takes as input a predefined number of final clusters. If you wanted, for instance, to create a 80:20 split, you could use the K-means algorithm with the number of clusters = 5. One example from the literature is [this paper](https://pubs.rsc.org/en/content/articlelanding/2019/sc/c8sc04175j), that uses:\n",
    "> *K-means clustering with K = 5 on MACCS fingerprints*\n",
    "\n",
    "The second version uses a clustering algorithm with a predefined threshold value. In this case, we can't know beforehand the final number of clusters, only control whether there will be more or less clusters by setting the cutoff value. For more details, read [this talktorial, that uses Butina clustering](https://projects.volkamerlab.org/teachopencadd/talktorials/T005_compound_clustering.html).\n",
    "\n",
    "In Deepchem the cluster split available is of the second type, and it also employs the Butina clustering algorithm from RDKit, an algorithm optimized for clustering molecular finerprints. The method requires RDKit to be installed and takes SMILES as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "221824c4-2ed6-4ecf-885c-c3054df662eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "\n",
    "butinasplitter = dc.splits.ButinaSplitter()\n",
    "train_butina, test_butina = butinasplitter.train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3db1ea86-6bc5-49f9-9596-0927c7dad5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1547, 1024), (1547, 1), (1547, 0), (1547,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_butina.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "270f4018-1cc6-466a-a653-da86643a69ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((387, 1024), (387, 1), (387, 0), (387,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_butina.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cea63bc7-b9f0-4dd7-ab23-2583d41af112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X1017</th>\n",
       "      <th>X1018</th>\n",
       "      <th>X1019</th>\n",
       "      <th>X1020</th>\n",
       "      <th>X1021</th>\n",
       "      <th>X1022</th>\n",
       "      <th>X1023</th>\n",
       "      <th>X1024</th>\n",
       "      <th>y</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CC(=O)OCC(=O)[C@@]1(O)CC[C@H]2[C@@H]3CC=C4CC(=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C[C@H]1C[C@H]2[C@@H]3CC=C4CC(=O)C=C[C@]4(C)[C@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C[C@]12C[C@H](O)[C@H]3[C@@H](CC=C4CC(=O)C=C[C@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C[C@]12CC(=O)C3[C@@H](CC=C4CC(=O)C=C[C@@]43C)[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C[C@]12C[C@H](O)[C@@]3(F)[C@@H](CC=C4CC(=O)C=C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  X3  X4  X5  X6  X7  X8  X9  X10  ...  X1017  X1018  X1019  X1020  \\\n",
       "0   0   0   0   0   0   0   0   0   0    0  ...      0      1      0      1   \n",
       "1   0   0   0   0   0   0   0   0   0    0  ...      0      0      0      1   \n",
       "2   0   0   0   0   0   0   0   0   0    0  ...      0      0      0      1   \n",
       "3   0   0   0   0   0   0   0   0   0    0  ...      0      0      0      1   \n",
       "4   0   0   0   0   0   0   0   0   0    0  ...      0      0      0      1   \n",
       "\n",
       "   X1021  X1022  X1023  X1024  y  \\\n",
       "0      0      0      0      0  1   \n",
       "1      1      0      0      0  0   \n",
       "2      0      0      0      0  0   \n",
       "3      0      0      0      0  0   \n",
       "4      1      0      0      0  0   \n",
       "\n",
       "                                                 ids  \n",
       "0  CC(=O)OCC(=O)[C@@]1(O)CC[C@H]2[C@@H]3CC=C4CC(=...  \n",
       "1  C[C@H]1C[C@H]2[C@@H]3CC=C4CC(=O)C=C[C@]4(C)[C@...  \n",
       "2  C[C@]12C[C@H](O)[C@H]3[C@@H](CC=C4CC(=O)C=C[C@...  \n",
       "3  C[C@]12CC(=O)C3[C@@H](CC=C4CC(=O)C=C[C@@]43C)[...  \n",
       "4  C[C@]12C[C@H](O)[C@@]3(F)[C@@H](CC=C4CC(=O)C=C...  \n",
       "\n",
       "[5 rows x 1026 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_butina.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5d0b0-c484-4cf3-94c9-4f88e540d21e",
   "metadata": {},
   "source": [
    "# Scaffold split\n",
    "\n",
    "Consists in splitting the data according to Bemis-Murcko scaffolds in a way that molecules with the same scaffold are either in the training set or in the test set, but not both. Usually, compounds belonging to the rarest scaffolds are put in the test set. This method might not be able to create perfect data splits because it depends on the particular scaffold distribution of a dataset.\n",
    "\n",
    "For more information, see: \n",
    "\n",
    "https://www.blopig.com/blog/2021/06/out-of-distribution-generalisation-and-scaffold-splitting-in-molecular-property-prediction/\n",
    "\n",
    "https://practicalcheminformatics.blogspot.com/2023/06/getting-real-with-molecular-property.html\n",
    "\n",
    "Deepchem's implementation requires RDKit to be installed and takes SMILES as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee53dc07-7021-4888-8e68-b93d7c4424d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "\n",
    "scaffoldsplitter = dc.splits.ScaffoldSplitter()\n",
    "train_scaffold, test_scaffold, = scaffoldsplitter.train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65180d22-80fd-469c-ab71-af751e6f0ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1547, 1024), (1547, 1), (1547, 0), (1547,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaffold.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36a76ca3-de0c-40e3-a82f-fa79fadddb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((387, 1024), (387, 1), (387, 0), (387,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scaffold.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b86a4a23-ec5d-406f-991e-d990a468bc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X1017</th>\n",
       "      <th>X1018</th>\n",
       "      <th>X1019</th>\n",
       "      <th>X1020</th>\n",
       "      <th>X1021</th>\n",
       "      <th>X1022</th>\n",
       "      <th>X1023</th>\n",
       "      <th>X1024</th>\n",
       "      <th>y</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>C[C@H](N)Cc1ccccc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CS(=O)(=O)c1ccc([C@@H](O)[C@@H](CO)NC(=O)C(Cl)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cc1c(OCC(C)N)c(C)ccc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CCCC(=O)Nc1cc(C(C)=O)c(OCC(O)CNC(C)C)cc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CCN(CC)C(=O)Nc1ccc(OCC(O)CNC(C)(C)C)c(C(C)=O)c1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  X3  X4  X5  X6  X7  X8  X9  X10  ...  X1017  X1018  X1019  X1020  \\\n",
       "0   0   1   0   0   0   0   0   0   0    0  ...      0      0      0      0   \n",
       "1   0   1   0   0   0   0   0   0   0    0  ...      0      0      0      0   \n",
       "2   0   1   0   0   0   0   0   0   0    0  ...      0      0      0      0   \n",
       "3   0   1   0   0   1   0   0   0   0    0  ...      0      1      0      0   \n",
       "4   1   1   0   0   0   0   0   0   0    0  ...      0      1      0      0   \n",
       "\n",
       "   X1021  X1022  X1023  X1024  y  \\\n",
       "0      0      0      0      0  1   \n",
       "1      0      0      0      0  1   \n",
       "2      0      0      0      0  1   \n",
       "3      0      0      0      0  1   \n",
       "4      0      0      0      0  1   \n",
       "\n",
       "                                                 ids  \n",
       "0                                 C[C@H](N)Cc1ccccc1  \n",
       "1  CS(=O)(=O)c1ccc([C@@H](O)[C@@H](CO)NC(=O)C(Cl)...  \n",
       "2                              Cc1c(OCC(C)N)c(C)ccc1  \n",
       "3           CCCC(=O)Nc1cc(C(C)=O)c(OCC(O)CNC(C)C)cc1  \n",
       "4    CCN(CC)C(=O)Nc1ccc(OCC(O)CNC(C)(C)C)c(C(C)=O)c1  \n",
       "\n",
       "[5 rows x 1026 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaffold.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b7819c-2d2f-4848-a970-9ee34fdcbe18",
   "metadata": {},
   "source": [
    "# Fingerprint split\n",
    "\n",
    "Splits are based on the Tanimoto similarity between ECFP4 fingerprints. Tries to split the data such that the molecules in each dataset are as different as possible from the ones in the other datasets.\n",
    "\n",
    "This looks similar to the \"Neighbor splits\" approach, in which the number of neighbors for each compound is computed, then, compounds with fewer neighbors are placed in the test set. A neighbor can be defined as a compound with similarity greater than a predefined threshold (0.5-0.7) according to some similarity metric (Tanimoto/cosine/Dice) on molecular fingerprints. \n",
    "\n",
    "Be aware that these methods are likely to create test sets that are too hard and, consequetly, the calculated metrics might underestimate true model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0b1201d-3907-426a-b7ff-22b2943359b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "\n",
    "fingerprintsplitter = dc.splits.FingerprintSplitter()\n",
    "train_fp, test_fp = fingerprintsplitter.train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60dbc5a5-660d-4b5f-976c-b8bc49f8865b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1547, 1024), (1547, 1), (1547, 0), (1547,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fp.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a695818-9c21-41cc-90d6-1948e2cef4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((387, 1024), (387, 1), (387, 0), (387,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fp.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ced343c0-f3e3-43aa-a763-bf0665b7fbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X1017</th>\n",
       "      <th>X1018</th>\n",
       "      <th>X1019</th>\n",
       "      <th>X1020</th>\n",
       "      <th>X1021</th>\n",
       "      <th>X1022</th>\n",
       "      <th>X1023</th>\n",
       "      <th>X1024</th>\n",
       "      <th>y</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cc1onc(-c2ccccc2Cl)c1C(=O)NC1C(=O)N2C1SC(C)(C)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>COc1ccc([C@@H]2Sc3ccccc3N(CCN(C)C)C(=O)C2OC(C)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N=C(N)NC(=O)c1nc(Cl)c(N)nc1N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nc1nnc(-c2cccc(Cl)c2Cl)c(N)n1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CCCC(C)C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  X3  X4  X5  X6  X7  X8  X9  X10  ...  X1017  X1018  X1019  X1020  \\\n",
       "0   0   1   0   0   0   1   0   0   0    0  ...      0      0      0      1   \n",
       "1   0   0   0   0   0   1   0   1   0    0  ...      0      1      0      1   \n",
       "2   0   0   0   0   0   0   0   0   0    0  ...      0      0      0      0   \n",
       "3   0   0   0   0   0   0   0   0   0    0  ...      0      0      0      0   \n",
       "4   0   1   0   0   0   0   0   0   0    0  ...      0      0      0      0   \n",
       "\n",
       "   X1021  X1022  X1023  X1024  y  \\\n",
       "0      0      0      0      0  1   \n",
       "1      0      0      0      0  1   \n",
       "2      0      0      0      0  1   \n",
       "3      0      0      0      0  1   \n",
       "4      0      0      0      0  1   \n",
       "\n",
       "                                                 ids  \n",
       "0  Cc1onc(-c2ccccc2Cl)c1C(=O)NC1C(=O)N2C1SC(C)(C)...  \n",
       "1  COc1ccc([C@@H]2Sc3ccccc3N(CCN(C)C)C(=O)C2OC(C)...  \n",
       "2                       N=C(N)NC(=O)c1nc(Cl)c(N)nc1N  \n",
       "3                      Nc1nnc(-c2cccc(Cl)c2Cl)c(N)n1  \n",
       "4                                           CCCC(C)C  \n",
       "\n",
       "[5 rows x 1026 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fp.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fafbc0-458a-4102-8628-a0bbede44d7a",
   "metadata": {},
   "source": [
    "# Temporal split\n",
    "\n",
    "Despite also being known as time-split cross-validation, this method consists in using a single train/test split, with newer instances being alocated to the test set. Contrast this to scikit-learn's [Time Series Split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html), that can generate K-splits for time series data.\n",
    "\n",
    "In [Time-Split Cross-Validation as a Method for Estimating the Goodness of Prospective Prediction (2013)](https://pubs.acs.org/doi/10.1021/ci400084k), Sheridan shows that using a single split to allocate either 10, 25 or 50% of the \"newest\" compounds in the test set can match well the R² for future data prediction, whereas a random split tends to be too optimistic about model performance.\n",
    "\n",
    "This implementation from Deepchem assumes that your dataset is properly ordered, with newer compounds at the bottom of the dataset. Therefore, it is just a simple index split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0868c8eb-5aa8-4c19-8910-94f95bb22e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "\n",
    "indexsplitter = dc.splits.IndexSplitter()\n",
    "train_dataset, test_dataset = indexsplitter.train_test_split(dataset, frac_train=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e3a67bf-08d1-420a-ae9e-760dd6359dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be similar to scikit-learn's train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16111d17-4c8c-458c-a43d-ce56c03d1cd3",
   "metadata": {},
   "source": [
    "# More options\n",
    "\n",
    "In addition to `train_test_split`, some of the other methods available in DeepChem include `train_valid_test_split`, which creates an additional validation set, and `k_fold_split`, which creates several splits for use in cross-validation (note that this might not always make sense, such as for time-split data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5491e24-e65e-43d9-9082-ae7df5ef7d49",
   "metadata": {},
   "source": [
    "# SIMPD - Simulated Time Split\n",
    "\n",
    "The temporal split has been shown as a good predictor of future model performance. However, date information is rarely available, especially on public assays. In [SIMPD: an Algorithm for Generating Simulated Time Splits for Validating Machine Learning Approaches (2023)](https://chemrxiv.org/engage/chemrxiv/article-details/6406049e6642bf8c8f10e189), Landrum et al. describe the SIMPD algorithm, which uses a genetic algorithm approach to create an approximate temporal split for any dataset. \n",
    "\n",
    "The authors identify that these simulated temporal splits reflect the properties expected for true temporal splits: descriptors that tend to increase over the course of a project, such as the “synthetic accessibility” score (compounds get more complex), heavy atom count and topological polar surface area (TPSA) also increase in the selected test sets relative to the training sets.\n",
    "\n",
    "The algorithm has been open-sourced on [GitHub](github.com/rinikerlab/molecular_time_series), but I didn't find it too easy to implement. It seems that SIMPD might be added to [RDKit - Prefer](https://github.com/rdkit/PREFER) soon, so I'll' keep it for a future Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca2db1-7810-4a78-9ad6-faa08d36bef2",
   "metadata": {},
   "source": [
    "# MUV\n",
    "\n",
    "In [Maximum Unbiased Validation (MUV) Data Sets for Virtual Screening Based on PubChem Bioactivity Data (2009)](https://pubs.acs.org/doi/10.1021/ci8002649), Rohren and Baumann present the MUV workflow to create unbiased datasets for virtual screening.\n",
    "\n",
    "The workflow consists in:\n",
    "- Removing compounds with a potential for unspecific bioactivity. For this, the authors implement filters for assay artifacts, frequent hitters,  autofluorescence, and luciferase inhibition. \n",
    "- Removing active compounds devoid of decoys (chemical space embedding filter)\n",
    "- Use of spatial statistics to adjust the spread of actives ($G$) and of actives and decoys ($F$), enforcing spatial randomness. Large values of $G$ indicate a high level of self-similarity among the actives, whereas small values of $F$ indicate a high degree of separation from the decoys. Therefore, the quantity $S = G - F$ can be seen an estimate of \"data clumping\", and the unbiasing approach can be summarized as \"adjusting the dataset to bring the value of $S$ close to zero\".\n",
    "\n",
    "I could not find the code for the MUV workflow, so let's check out the next approach, which is based on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ce8f90-1803-4510-9d72-5a94396b267f",
   "metadata": {},
   "source": [
    "# AVE\n",
    "\n",
    "In [Most Ligand-Based Classification Benchmarks Reward Memorization Rather than Generalization (2018)](https://pubs.acs.org/doi/abs/10.1021/acs.jcim.7b00403), Wallach and Heifets investigate the phenomenon of \"undetected overfitting\", which is a consequence of having redundant information in both training an test sets, that is, active-active and inactive-inactive similarities in both sets. Inspired by the MUV approach, the AVE redundancy measure, or **AVE bias**, was proposed to measure validation set bias. The authors state that:\n",
    "\n",
    "> the amount of AVE bias strongly correlates with the performance of ligand-based predictive methods irrespective of the predicted property, chemical fingerprint, similarity measure, or previously applied unbiasing techniques\n",
    "\n",
    "In essence, the AVE bias:\n",
    "\n",
    "> describes the ability of 1-NN to solve a validation set by memorizing the training data... tests with high AVE bias are easy to solve\n",
    "\n",
    "It is shown that even time-split datasets can show significant bias, mostly because there is an intrinsic bias in compounds that are selected for synthesis and testing. Therefore, a splitting method is proposed to minimize redundancy bias. The authors, however, alert for its limitations:\n",
    "\n",
    "> For cases where the available data are scarce, we proposed an algorithm that minimizes the AVE bias in test cases... uses a genetic algorithm to partition the available data into training and validation subsets with reduced bias. The algorithm is a heuristic search\n",
    "\n",
    "> we claim neither that the algorithm is optimal nor that it is guaranteed to succeed. There is a risk that new biases are introduced into the test, as with clustering and MUV unbiasing. In many cases, however, test cases can be successfully unbiased and used in evaluations\n",
    "\n",
    "And make some final suggestions:\n",
    "\n",
    "> we suggest that cheminformaticians measure and report biases in their tests, and we provide our code to compute AVE biases. Tests with high bias can be excluded from consideration or unbiased with the provided code. Baseline predictive performance, such as from 1-NN, should also be included in the results.\n",
    "\n",
    "Two Python scripts are available from the paper's Supporting Information: \n",
    "`analyze_AVE_bias.py` measures the bias of a dataset that was already split into training and test (.smi file, tab- or space-separated). `remove_AVE_bias.py` takes an entire dataset and creates an optimal split using to their algorithm. \n",
    "\n",
    "I have updated the scripts to work with Python 3 and fixed some indentation mistakes. The updated files can be found [in this folder](https://github.com/rflameiro/Python_e_Quiminformatica/tree/main/modules). I'll be using the default options on this example, but take a look at the script for the available options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c545e3-56ad-4c72-a31c-861b0b62954d",
   "metadata": {},
   "source": [
    "## analyze_AVE_bias\n",
    "\n",
    "Let's compare the random and scaffold splits. The AVE bias is the final value output by the script: (AA-AI)+(II-IA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a6c9c39-2ecb-4ded-9942-c3d5065ca619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas DataFrame\n",
    "train_random_df = train_random.to_dataframe()\n",
    "test_random_df = test_random.to_dataframe()\n",
    "\n",
    "train_scaffold_df = train_scaffold.to_dataframe()\n",
    "test_scaffold_df = test_scaffold.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8dafbf84-a6a5-4dce-a9b5-51c95de85f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframes_to_smi(df_train, df_test, label=\"\"):\n",
    "    \"\"\"\n",
    "    Function to write .smi inputs to analyze_AVE_bias.py\n",
    "    df_train, df_test: Pandas DataFrame with a SMILES column labeled as \"ids\", and the binary target column \"y\"\n",
    "    label: will be used to name the generated .smi files. Use it to compare splits, \n",
    "        e.g., \"random\", \"scaffold\", \"temporal\"\n",
    "\n",
    "    I modified the function to output the results inside the notebook, using print().\n",
    "    In case you prefer to create a .txt with the results, you can modify the script by (un)commenting where indicated\n",
    "    \"\"\"\n",
    "    active_training = df_train[df_train[\"y\"] == 1][\"ids\"].to_list()\n",
    "    inactive_training = df_train[df_train[\"y\"] == 0][\"ids\"].to_list()\n",
    "    active_test = df_test[df_test[\"y\"] == 1][\"ids\"].to_list()\n",
    "    inactive_test = df_test[df_test[\"y\"] == 0][\"ids\"].to_list()\n",
    "\n",
    "    active_training_path = \"active_training_\" + label + \".smi\"   \n",
    "    with open(active_training_path,'w+') as file:\n",
    "        file.write(' \\n'.join(active_training))\n",
    "    print(active_training_path)\n",
    "\n",
    "    inactive_training_path = \"inactive_training_\" + label + \".smi\"   \n",
    "    with open(inactive_training_path,'w+') as file:\n",
    "        file.write(' \\n'.join(inactive_training))\n",
    "    print(inactive_training_path)\n",
    "    \n",
    "    active_test_path = \"active_test_\" + label + \".smi\"   \n",
    "    with open(active_test_path,'w+') as file:\n",
    "        file.write(' \\n'.join(active_test))\n",
    "    print(active_test_path)\n",
    "\n",
    "    inactive_test_path = \"inactive_test_\" + label + \".smi\"   \n",
    "    with open(inactive_test_path,'w+') as file:\n",
    "        file.write(' \\n'.join(inactive_test))\n",
    "    print(inactive_test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e07a678-2289-4c3a-88a1-cffdd5c51267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_training_random.smi\n",
      "inactive_training_random.smi\n",
      "active_test_random.smi\n",
      "inactive_test_random.smi\n"
     ]
    }
   ],
   "source": [
    "# write .smi files - random\n",
    "dataframes_to_smi(train_random_df, test_random_df, label=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd942e5-ada7-46cd-97d2-5ee707a93856",
   "metadata": {},
   "source": [
    "Note: I modified the script to print the results on the Notebook, so the `-outFile` argument will not be used for anything, but it is still required to run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4bf67c52-bc53-490d-a70d-43bb761f2a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#ActTrain = 1177 \n",
      "#InactTrain = 370 \n",
      "#ActTest = 299 \n",
      "#InactTest = 88 \n",
      "knn1 = 0.834 \n",
      "lr = 0.909 \n",
      "rf = 0.942 \n",
      "svm = 0.921 \n",
      "AA-AI = 0.221 \n",
      "II-IA = 0.169 \n",
      "(AA-AI)+(II-IA) = 0.390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:38:20] WARNING: no name column found on line 1176\n",
      "[15:38:20] WARNING: no name column found on line 369\n",
      "[15:38:20] WARNING: no name column found on line 298\n",
      "[15:38:20] WARNING: no name column found on line 87\n",
      "C:\\Users\\rafae\\miniconda3\\envs\\deepchem-test\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# run script\n",
    "! python analyze_AVE_bias.py -activeMolsTraining active_training_random.smi -inactiveMolsTraining inactive_training_random.smi -activeMolsTesting active_test_random.smi -inactiveMolsTesting inactive_test_random.smi -outFile ave_results_random.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38f733ca-38de-456e-a5cc-0955b0791938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_training_scaffold.smi\n",
      "inactive_training_scaffold.smi\n",
      "active_test_scaffold.smi\n",
      "inactive_test_scaffold.smi\n"
     ]
    }
   ],
   "source": [
    "# write .smi files - scaffold\n",
    "dataframes_to_smi(train_scaffold_df, test_scaffold_df, label=\"scaffold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4714ef0-3a17-47a8-b232-d84ec1244ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#ActTrain = 1274 \n",
      "#InactTrain = 273 \n",
      "#ActTest = 202 \n",
      "#InactTest = 185 \n",
      "knn1 = 0.712 \n",
      "lr = 0.818 \n",
      "rf = 0.839 \n",
      "svm = 0.837 \n",
      "AA-AI = 0.158 \n",
      "II-IA = 0.048 \n",
      "(AA-AI)+(II-IA) = 0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:40:28] WARNING: no name column found on line 1273\n",
      "[15:40:28] WARNING: no name column found on line 272\n",
      "[15:40:28] WARNING: no name column found on line 201\n",
      "[15:40:29] WARNING: no name column found on line 184\n",
      "C:\\Users\\rafae\\miniconda3\\envs\\deepchem-test\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# run script\n",
    "! python analyze_AVE_bias.py -activeMolsTraining active_training_scaffold.smi -inactiveMolsTraining inactive_training_scaffold.smi -activeMolsTesting active_test_scaffold.smi -inactiveMolsTesting inactive_test_scaffold.smi -outFile ave_results_scaffold.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916fe1b-4b65-4f74-ada6-3dfd83f630ae",
   "metadata": {},
   "source": [
    "As we can see, the bias of the scaffold split (0.205) is smaller than that of the random split (0.390). Notice how the scaffold split decreases both the values of AA-AI and II-IA. \n",
    "\n",
    "AA-AI is a measure of how clumped the test actives are among the training actives, and II-IA, similarly, measures the clumping among the inactives. This means that while scaffold splitting is able to make test actives less similar to training actives, its main strength in this example was to decrease significantly the inactive-inactive similarities among the training-test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb980d4-d466-4507-923b-ecf190eb9fcb",
   "metadata": {},
   "source": [
    "## remove_AVE_bias\n",
    "\n",
    "Let's see if we can get an improvement over the scaffold split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "809dad25-85cf-47d1-ae4a-56760034297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_smi(df, label=\"\"):\n",
    "    \"\"\"\n",
    "    Function to write .smi inputs to remove_AVE_bias.py\n",
    "    df: Pandas DataFrame with a SMILES column labeled as \"ids\", and the binary target column \"y\"\n",
    "    label: will be used to name the generated .smi files.\n",
    "    \"\"\"\n",
    "    active_mols = df[df[\"y\"] == 1][\"ids\"].to_list()\n",
    "    inactive_mols = df[df[\"y\"] == 0][\"ids\"].to_list()\n",
    "\n",
    "    active_mols_path = \"active_mols_\" + label + \".smi\"   \n",
    "    with open(active_mols_path,'w+') as file:\n",
    "        file.write(' \\n'.join(active_mols))\n",
    "    print(active_mols_path)\n",
    "\n",
    "    inactive_mols_path = \"inactive_mols_\" + label + \".smi\"   \n",
    "    with open(inactive_mols_path,'w+') as file:\n",
    "        file.write(' \\n'.join(inactive_mols))\n",
    "    print(inactive_mols_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cf093b4-6a7b-487e-8621-4470b5b4318c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cc1onc(-c2ccccc2Cl)c1C(=O)NC1C(=O)N2C1SC(C)(C)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCN1CCN(C(=O)NC(C(=O)NC2C(=O)N3C(C(=O)O)=C(CSc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN(C)C1C(=O)C(C(=O)NCN2CCCC2)C(=O)[C@@]2(O)C(=...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cc1nccn1CC1CCc2c(C1=O)c1ccccc1n2C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COc1ccc([C@@H]2Sc3ccccc3N(CCN(C)C)C(=O)C2OC(C)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ids  y\n",
       "0  Cc1onc(-c2ccccc2Cl)c1C(=O)NC1C(=O)N2C1SC(C)(C)...  1\n",
       "1  CCN1CCN(C(=O)NC(C(=O)NC2C(=O)N3C(C(=O)O)=C(CSc...  1\n",
       "2  CN(C)C1C(=O)C(C(=O)NCN2CCCC2)C(=O)[C@@]2(O)C(=...  1\n",
       "3                  Cc1nccn1CC1CCc2c(C1=O)c1ccccc1n2C  1\n",
       "4  COc1ccc([C@@H]2Sc3ccccc3N(CCN(C)C)C(=O)C2OC(C)...  1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_smi.copy()\n",
    "df.columns = [\"ids\", \"y\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27a19da8-3598-449c-a1c7-16591fcc303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_mols_remove_bias.smi\n",
      "inactive_mols_remove_bias.smi\n"
     ]
    }
   ],
   "source": [
    "dataframe_to_smi(df, label=\"remove_bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e55fb47f-925d-45a7-b535-a11d8b56e60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 1476 actives and 458 inactives\n",
      "calc aa_D_ref\n",
      "calc ii_D_ref\n",
      "calc ai_D_ref\n",
      "done\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 1 fullPopObj= 0.367 topPopObj= 0.337 finalPopObj= 0.311 minObj= 99999\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 2 fullPopObj= 0.341 topPopObj= 0.315 finalPopObj= 0.297 minObj= 0.311\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 3 fullPopObj= 0.318 topPopObj= 0.291 finalPopObj= 0.262 minObj= 0.297\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 4 fullPopObj= 0.298 topPopObj= 0.271 finalPopObj= 0.245 minObj= 0.262\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 5 fullPopObj= 0.279 topPopObj= 0.25 finalPopObj= 0.232 minObj= 0.245\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 6 fullPopObj= 0.261 topPopObj= 0.235 finalPopObj= 0.209 minObj= 0.232\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 7 fullPopObj= 0.242 topPopObj= 0.215 finalPopObj= 0.207 minObj= 0.209\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 8 fullPopObj= 0.222 topPopObj= 0.2 finalPopObj= 0.189 minObj= 0.207\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 9 fullPopObj= 0.209 topPopObj= 0.184 finalPopObj= 0.163 minObj= 0.189\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 10 fullPopObj= 0.192 topPopObj= 0.163 finalPopObj= 0.142 minObj= 0.163\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 11 fullPopObj= 0.169 topPopObj= 0.147 finalPopObj= 0.13 minObj= 0.142\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 12 fullPopObj= 0.15 topPopObj= 0.128 finalPopObj= 0.112 minObj= 0.13\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 13 fullPopObj= 0.132 topPopObj= 0.114 finalPopObj= 0.095 minObj= 0.112\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 14 fullPopObj= 0.119 topPopObj= 0.103 finalPopObj= 0.086 minObj= 0.095\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 15 fullPopObj= 0.108 topPopObj= 0.089 finalPopObj= 0.077 minObj= 0.086\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 16 fullPopObj= 0.094 topPopObj= 0.081 finalPopObj= 0.071 minObj= 0.077\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 17 fullPopObj= 0.086 topPopObj= 0.072 finalPopObj= 0.063 minObj= 0.071\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 18 fullPopObj= 0.076 topPopObj= 0.062 finalPopObj= 0.05 minObj= 0.063\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 19 fullPopObj= 0.066 topPopObj= 0.05 finalPopObj= 0.043 minObj= 0.05\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 20 fullPopObj= 0.059 topPopObj= 0.047 finalPopObj= 0.034 minObj= 0.043\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 21 fullPopObj= 0.05 topPopObj= 0.037 finalPopObj= 0.022 minObj= 0.034\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 22 fullPopObj= 0.041 topPopObj= 0.03 finalPopObj= 0.026 minObj= 0.022\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 23 fullPopObj= 0.035 topPopObj= 0.024 finalPopObj= 0.015 minObj= 0.022\n",
      "breed\n",
      "calculate objectives for the population\n",
      "remove similar sets\n",
      "removing 0 similar sets\n",
      "population size after similarity filter:  100\n",
      "select the next generation\n",
      "iter= 24 fullPopObj= 0.028 topPopObj= 0.016 finalPopObj= 0.002 minObj= 0.015\n",
      "Done. Total running time: 397.103 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:51:24] WARNING: no name column found on line 1475\n",
      "[12:51:24] WARNING: no name column found on line 457\n"
     ]
    }
   ],
   "source": [
    "# remove_AVE_bias.py\n",
    "! python remove_AVE_bias.py -activeMols active_mols_remove_bias.smi -inactiveMols inactive_mols_remove_bias.smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad35708-76d5-40cc-b98f-316d9dcd9c1e",
   "metadata": {},
   "source": [
    "Now let's see how the bias of this AVE split compares to that of the other splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01e3ccc1-0078-42ec-882d-bb8dcb0439f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#ActTrain = 1174 \n",
      "#InactTrain = 360 \n",
      "#ActTest = 290 \n",
      "#InactTest = 83 \n",
      "knn1 = 0.523 \n",
      "lr = 0.747 \n",
      "rf = 0.738 \n",
      "svm = 0.758 \n",
      "AA-AI = 0.160 \n",
      "II-IA = -0.158 \n",
      "(AA-AI)+(II-IA) = 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\miniconda3\\envs\\deepchem-test\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2182: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "! python analyze_AVE_bias.py -activeMolsTraining actives.T.smi -inactiveMolsTraining inactives.T.smi -activeMolsTesting actives.V.smi -inactiveMolsTesting inactives.V.smi -outFile ave_results_AVE_split.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e837256a-bc50-41af-a0ed-b14f51a7a42e",
   "metadata": {},
   "source": [
    "The overall bias is much smaller than that of the scaffold split. However, notice how the AA-AI factor is approximately the same, while II-IA has become negative. This means that test inactives are generally more similar to training actives than to training inactives, and that classification of inactives will be more challenging. This might be a problem or not, depending on your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a479205e-811d-4bb8-aaed-f36299616edc",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "| Splitting method | Bias | # training actives | # training inactives | # test actives | # test inactives |\n",
    "|---|---|---|---|---|---|\n",
    "| Random split | 0.390 | 1177 | 370 | 299  | 88 |\n",
    "| Scaffold split | 0.205 | 1274 | 273 | 202 | 185 |\n",
    "| AVE split | 0.002 | 1174 | 360 | 290 | 83 |\n",
    "\n",
    "In summary, the scaffold split is less biased than the random split, but it still has a significant bias compared to the AVE split. From the paper, bias values in the range 0.1-0.2 already indicate datasets that can be easily \"solved\" by all the algorithms tested (LR, SVM, RF, 1-NN), that is, achieving an AUC > 0.9. \n",
    "\n",
    "In our example, the bias comes mostly from the similarities among training/test actives, and this bias was not removed by the AVE split. The similary among inactives, on the other hand, was significantly altered by the split, which went as far as making it harder to differentiate test inactives from training actives than to training inactives. \n",
    "\n",
    "Since not many compounds were lost in the process, it might be a good idea to use the AVE split in this case. Expect, however, a drop in performance, since some test inactives are likely to be misclassified as actives. You can try different molecular repreesentations to overcome this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1692afc-5184-4bed-95ff-371451353eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
